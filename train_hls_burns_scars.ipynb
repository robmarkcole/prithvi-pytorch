{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/prithvi-pytorch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Replace 'your/directory/path' with the path to the directory you want to set as the current working directory\n",
    "os.chdir('/teamspace/studios/this_studio/prithvi-pytorch')\n",
    "\n",
    "# To verify that the current working directory has been changed, you can use:\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torchgeo.trainers import SemanticSegmentationTask\n",
    "\n",
    "from prithvi_pytorch import PrithviUnet\n",
    "from prithvi_pytorch.datasets import HLSBurnScarsDataModule\n",
    "\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import (\n",
    "    MulticlassAccuracy,\n",
    "    MulticlassF1Score,\n",
    "    MulticlassJaccardIndex,\n",
    ")\n",
    "from torchmetrics.wrappers import ClasswiseWrapper\n",
    "\n",
    "import wandb\n",
    "\n",
    "CKPT_PATH = \"weights/Prithvi_100M.pt\"\n",
    "CFG_PATH = \"weights/Prithvi_100M_config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrithviSegmentationTask(SemanticSegmentationTask):\n",
    "    def configure_models(self):\n",
    "        self.model = PrithviUnet(\n",
    "            num_classes=self.hparams[\"num_classes\"],\n",
    "            cfg_path=CFG_PATH,\n",
    "            ckpt_path=CKPT_PATH,\n",
    "            in_chans=self.hparams[\"in_channels\"],\n",
    "            img_size=512,\n",
    "            n=[2, 5, 8, 11],\n",
    "            norm=False,\n",
    "            decoder_channels=[256, 128, 64, 32],\n",
    "            freeze_encoder=False,\n",
    "        )\n",
    "\n",
    "    def configure_metrics(self) -> None:\n",
    "        \"\"\"Initialize the performance metrics.\"\"\"\n",
    "        num_classes: int = self.hparams[\"num_classes\"]\n",
    "        ignore_index: Optional[int] = self.hparams[\"ignore_index\"]\n",
    "        metrics = MetricCollection(\n",
    "            {\n",
    "                \"accuracy\": ClasswiseWrapper(\n",
    "                    MulticlassAccuracy(\n",
    "                        num_classes=num_classes, ignore_index=ignore_index, average=None\n",
    "                    ),\n",
    "                ),\n",
    "                \"jaccard\": ClasswiseWrapper(\n",
    "                    MulticlassJaccardIndex(\n",
    "                        num_classes=num_classes, ignore_index=ignore_index, average=None\n",
    "                    ),\n",
    "                ),\n",
    "                \"f1\": ClasswiseWrapper(\n",
    "                    MulticlassF1Score(\n",
    "                        num_classes=num_classes, ignore_index=ignore_index, average=None\n",
    "                    ),\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "        self.train_metrics = metrics.clone(prefix=\"train_\")\n",
    "        self.val_metrics = metrics.clone(prefix=\"val_\")\n",
    "        self.test_metrics = metrics.clone(prefix=\"test_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = PrithviSegmentationTask(\n",
    "    in_channels=6, num_classes=2, loss=\"focal\", lr=1e-3, patience=10, ignore_index=0\n",
    ")\n",
    "datamodule = HLSBurnScarsDataModule(\n",
    "    root=\"data/hls_burn_scars\",\n",
    "    batch_size=4,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "datamodule.setup('fit')\n",
    "datamodule.setup('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "540"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datamodule.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datamodule.test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(\n",
    "    project=\"prithvi\", \n",
    "    log_model=True, # True or 'all'\n",
    "    save_dir = \"wandb_logs\"\n",
    ")\n",
    "\n",
    "trainer = lightning.Trainer(\n",
    "    accelerator=\"gpu\", \n",
    "    logger=wandb_logger, \n",
    "    max_epochs=20, \n",
    "    precision=\"16-mixed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | FocalLoss        | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | test_metrics  | MetricCollection | 0     \n",
      "4 | model         | PrithviUnet      | 119 M \n",
      "---------------------------------------------------\n",
      "118 M     Trainable params\n",
      "1.3 M     Non-trainable params\n",
      "119 M     Total params\n",
      "479.962   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ea4872bcac474b8519fae9207b2c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The `.compute()` return of the metric logged as 'val_accuracy' must be a tensor. Found {'multiclassaccuracy_0': tensor(0., device='cuda:0'), 'multiclassaccuracy_1': tensor(0.0019, device='cuda:0')}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(module, datamodule)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    545\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    546\u001b[0m )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    582\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:989\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    986\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    991\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    994\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1033\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[1;32m   1032\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1033\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m   1034\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1035\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1062\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1059\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1061\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1062\u001b[0m val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1064\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1066\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:141\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_dataloader_outputs()\n\u001b[0;32m--> 141\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mon_run_end()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:253\u001b[0m, in \u001b[0;36m_EvaluationLoop.on_run_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_logger_connector\u001b[39m.\u001b[39m_evaluation_epoch_end()\n\u001b[1;32m    252\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_on_evaluation_epoch_end()\n\u001b[1;32m    255\u001b[0m logged_outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logged_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logged_outputs, []  \u001b[39m# free memory\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39m# include any logged outputs on epoch_end\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:331\u001b[0m, in \u001b[0;36m_EvaluationLoop._on_evaluation_epoch_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(trainer, hook_name)\n\u001b[1;32m    329\u001b[0m call\u001b[39m.\u001b[39m_call_lightning_module_hook(trainer, hook_name)\n\u001b[0;32m--> 331\u001b[0m trainer\u001b[39m.\u001b[39;49m_logger_connector\u001b[39m.\u001b[39;49mon_epoch_end()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:187\u001b[0m, in \u001b[0;36m_LoggerConnector.on_epoch_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_epoch_end\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_loop_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m     metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetrics\n\u001b[1;32m    188\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_progress_bar_metrics\u001b[39m.\u001b[39mupdate(metrics[\u001b[39m\"\u001b[39m\u001b[39mpbar\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    189\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_metrics\u001b[39m.\u001b[39mupdate(metrics[\u001b[39m\"\u001b[39m\u001b[39mcallback\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:226\u001b[0m, in \u001b[0;36m_LoggerConnector.metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m on_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_loop_iter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_results \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_results\u001b[39m.\u001b[39;49mmetrics(on_step)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:475\u001b[0m, in \u001b[0;36m_ResultCollection.metrics\u001b[0;34m(self, on_step)\u001b[0m\n\u001b[1;32m    471\u001b[0m metrics \u001b[39m=\u001b[39m _METRICS(callback\u001b[39m=\u001b[39m{}, log\u001b[39m=\u001b[39m{}, pbar\u001b[39m=\u001b[39m{})\n\u001b[1;32m    473\u001b[0m \u001b[39mfor\u001b[39;00m _, result_metric \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_items():\n\u001b[1;32m    474\u001b[0m     \u001b[39m# extract forward_cache or computed from the _ResultMetric\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_cache(result_metric, on_step)\n\u001b[1;32m    476\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Tensor):\n\u001b[1;32m    477\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:446\u001b[0m, in \u001b[0;36m_ResultCollection._get_cache\u001b[0;34m(result_metric, on_step)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(cache, Tensor):\n\u001b[0;32m--> 446\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    447\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe `.compute()` return of the metric logged as \u001b[39m\u001b[39m{\u001b[39;00mresult_metric\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mname\u001b[39m!r}\u001b[39;00m\u001b[39m must be a tensor.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Found \u001b[39m\u001b[39m{\u001b[39;00mcache\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m         )\n\u001b[1;32m    450\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result_metric\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39menable_graph:\n\u001b[1;32m    451\u001b[0m         \u001b[39mreturn\u001b[39;00m cache\u001b[39m.\u001b[39mdetach()\n",
      "\u001b[0;31mValueError\u001b[0m: The `.compute()` return of the metric logged as 'val_accuracy' must be a tensor. Found {'multiclassaccuracy_0': tensor(0., device='cuda:0'), 'multiclassaccuracy_1': tensor(0.0019, device='cuda:0')}"
     ]
    }
   ],
   "source": [
    "trainer.fit(module, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4d216d02d843838a8ce420b5ea1919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">         Test metric         </span>┃<span style=\"font-weight: bold\">        DataLoader 0         </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_MulticlassAccuracy   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">             1.0             </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassJaccardIndex </span>│<span style=\"color: #800080; text-decoration-color: #800080\">             1.0             </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    7.786973732493152e-09    </span>│\n",
       "└─────────────────────────────┴─────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m        Test metric        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       DataLoader 0        \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            1.0            \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassJaccardIndex\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m            1.0            \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   7.786973732493152e-09   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└─────────────────────────────┴─────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 7.786973732493152e-09,\n",
       "  'test_MulticlassAccuracy': 1.0,\n",
       "  'test_MulticlassJaccardIndex': 1.0}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(module, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae1f1e24078455ab7ef80ef897bf9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1107.939 MB of 1107.939 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_MulticlassAccuracy</td><td>▁</td></tr><tr><td>test_MulticlassJaccardIndex</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_MulticlassAccuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_MulticlassJaccardIndex</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▄▆▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>val_MulticlassAccuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_MulticlassJaccardIndex</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▃▂▃▃▄▁▁▃▁▁▂▂▅▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>test_MulticlassAccuracy</td><td>1.0</td></tr><tr><td>test_MulticlassJaccardIndex</td><td>1.0</td></tr><tr><td>test_loss</td><td>0.0</td></tr><tr><td>train_MulticlassAccuracy</td><td>1.0</td></tr><tr><td>train_MulticlassJaccardIndex</td><td>1.0</td></tr><tr><td>train_loss</td><td>0.0</td></tr><tr><td>trainer/global_step</td><td>2700</td></tr><tr><td>val_MulticlassAccuracy</td><td>1.0</td></tr><tr><td>val_MulticlassJaccardIndex</td><td>1.0</td></tr><tr><td>val_loss</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wandering-pyramid-1</strong> at: <a href='https://wandb.ai/robmarkcole/prithvi/runs/bkccjwa7' target=\"_blank\">https://wandb.ai/robmarkcole/prithvi/runs/bkccjwa7</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>wandb_logs/wandb/run-20231211_143110-bkccjwa7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
